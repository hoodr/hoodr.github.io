{"pageProps":{"post":{"title":"Getting into Computer Vision with Rust","date":"2023-10-25T00:00:00Z","slug":"rust-cv-pt1","content":"\n# Getting into Computer Vision with Rust\n\nComputer vision is something I've had an interest in for ages. It combined my\nlove for photo/video with math and computer science. However, I never really had\na chance to explore this avenue at university. As such, I had to slowly get into\nthis outside of school after work and we all know how hard a side project can\nget. So now I've decided that it's about time I really put hands to keyboard and\ndive into computer vision and my favorite programming language, Rust. On the\nadvice of some far more knowledgable folk than me, I've decided to start a blog\nand chronicle this journey.\n\n## The Project\n\nWay back in the day (2016) I was fascinated with a phd thesis by Jakob Engel,\nthen a phd student at TUM, the Technical University of Munich. The thesis title\nwas \"DSO: Direct Sparse Odeometry\". Visual odometry is defined as \"the process\nof determining the position and orientation of a robot by analyzing the\nassociated camera images.\" Now, the standard approach to visual odometry is the\nfollowing:\n1. Acquire input images\n2. Apply image correction\n3. Feature detection\n4. Check flow field vectors for potential tracking errors and remove outliers\n5. Estimation of the camera motion from the optical flow\n  a. Kalman filter for state estimate distribution maintenance.\n  b. Find the geometric and 3D properties of the features that minimize a cost\n     function based on the re-projection error between two adjacent images. This\n     can be done by mathematical minimization or random sampling. \n6. Periodic repopulation of trackpoints to maintain coverage across the image\n\nJakob Engel and his advisors first proposed this in his paper \"LSD-SLAM:\nLarge-Scale Direct Monocular SLAM\" which states in the abstract:\n\n> We propose a direct (feature-less) monocular SLAM algorithm which, in contrast\nto current state-of-the-art regarding direct methods, allows to build\nlarge-scale, consistent maps of the environment. Along with highly accurate pose\nestimation based on direct image alignment, the 3D environment is reconstructed\nin real-time as pose-graph of keyframes with associated semi-dense depth maps.\nThese are obtained by filtering over a large number of pixelwise small-baseline\nstereo comparisons. The explicitly scale-drift aware formulation allows the\napproach to operate on challenging sequences including large variations in scene\nscale. Major enablers are two key novelties: (1) a novel direct tracking method\nwhich operates on sim(3), thereby explicitly detecting scale-drift, and (2) an\nelegant probabilistic solution to include the effect of noisy depth values into\ntracking. The resulting direct monocular SLAM system runs in real-time on a CPU.\n\nHe then went and built a practical application of this paper with \"DSO\", which\napplied this direct approach. DSO is 5 years old now and while it may not be the\nmost novel and/or current approach, but it seems to me like an ideal candidate\nto translate from its original c++ into Rust as a way to show how Rust can\nreplace c++ for applications like this, and take a deep dive into the practical\napplication of computer vision theory. I'd really like to thank Jakob for open\nsourcing the code for his project as well as the datasets that he used. It's\nreally cool to see the working code of someone who clearly poured a lot of time\nand energy to see out the vision of the original proposal. This blog post has\nbeen a long time coming, and I hope it to be a motivating factor in getting this\nproject over the proverbial finish line while also being an awesome (re)learning\nexperience (linear algebra was one of my favorite courses at university and it\ndeeply saddens me just how much I've forgotten). Anyways, stay tuned for more!\n","ogImage":{"url":"/assets/blog/rust-cv-pt1/cover.jpg"},"coverImage":"/assets/blog/rust-cv-pt1/cover.jpg"}},"__N_SSG":true}